
4.社区问答json版(webtext2019zh) ：大规模高质量数据集
-------------------------------------------------------------------------

#### 410万个问答( 过滤后数据3.7G，压缩文件1.7G；数据跨度：2015-2016年)

<a href='https://drive.google.com/open?id=1u2yW_XohbYL2YAK6Bzc5XrngHstQTf0v'>Google Drive下载</a>


#### 数据描述

含有410万个预先过滤过的、高质量问题和回复。每个问题属于一个【话题】，总共有2.8万个各式话题，话题包罗万象。

从1400万个原始问答中，筛选出至少获得3个点赞以上的的答案，代表了回复的内容比较不错或有趣，从而获得高质量的数据集。

除了对每个问题对应一个话题、问题的描述、一个或多个回复外，每个回复还带有点赞数、回复ID、回复者的标签。

数据集划分：数据去重并分成三个部分。训练集：412万；验证集：6.8万；测试集a：6.8万；测试集b，不提供下载。


#### 可能的用途：
    
    1）构建百科类问答：输入一个问题，构建检索系统得到一个回复或生产一个回复；或根据相关关键词从，社区问答库中筛选出你相关的领域数据
    
    2）训练话题预测模型：输入一个问题(和或描述)，预测属于话题。
    
    3）训练社区问答(cQA)系统：针对一问多答的场景，输入一个问题，找到最相关的问题，在这个基础上基于不同答案回复的质量、
    
      问题与答案的相关性，找到最好的答案。

    4）做为通用中文语料，做大模型预训练的语料或训练词向量。其中类别信息也比较有用，可以用于做监督训练，从而构建更好句子表示的模型、句子相似性任务等。
    
    5）结合点赞数量这一额外信息，预测回复的受欢迎程度或训练答案评分系统。

#### 结构：

    {"qid":<qid>,"title":<title>,"desc":<desc>,"topic":<topic>,"star":<star>,"content":<content>,
    
    "answer_id":<answer_id>,"answerer_tags":<answerer_tags>}
    
    其中，qid是问题的id，title是问题的标题，desc是问题的描述，可以为空；topic是问题所属的话题，star是该回复的点赞个数，
    
    content是回复的内容，answer_id是回复的ID,answerer_tags是回复者所携带的标签

#### 例子：
    
    {"qid": 65618973, "title": "AlphaGo只会下围棋吗？阿法狗能写小说吗？", "desc": "那么现在会不会有智能机器人能从事文学创作？<br>如果有，能写出什么水平的作品？", "topic": "机器人", "star": 3, "content": "AlphaGo只会下围棋，因为它的设计目的，架构，技术方案以及训练数据，都是围绕下围棋这个核心进行的。它在围棋领域的突破，证明了深度学习深度强化学习MCTS技术在围棋领域的有效性，并且取得了重大的PR效果。AlphaGo不会写小说，它是专用的，不会做跨出它领域的其它事情，比如语音识别，人脸识别，自动驾驶，写小说或者理解小说。如果要写小说，需要用到自然语言处理（NLP））中的自然语言生成技术，那是人工智能领域一个", "answer_id": 545576062, "answerer_tags": "人工智能@游戏业"}
  

<img src="https://github.com/brightmart/nlp_chinese_corpus/blob/master/resources/img/webtext2019zh.png"  width="100%" height="100%" />


#### 在该数据集上的公开评测和任务：

任务1： 话题预测。

报告包括：#1）验证集上准确率；#2）采用的模型、方法描述、运行方式，1页PDF；#3）可运行的源代码(可选)

基于#2和#3，我们会在测试集上做测试，并报告测试集上的准确率；只提供了#1和#2的队伍，验证集上的成绩依然可以被显示出来，但会被标记为未验证。

任务2：训练社区问答(cQA)系统。

要求：评价指标采用MAP，构建一个适合排序问题的测试集，并报告在该测试集上的效果。

任务3：使用该数据集（webtext2019zh)，参考OpenAI的GPT-2，训练中文的文本写作模型、测试在其他数据集上的zero-shot的效果，或测评语言模型的效果。

<br>
